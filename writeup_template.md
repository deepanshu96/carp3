**Behavioral Cloning Project**

The goals of this project are the following:
* Use the simulator to collect data of good driving behavior
* Build, a convolution neural network in Keras that predicts steering angles from images
* Train and validate the model with a training and validation set
* Test that the model successfully drives around track one without leaving the road
* Summarize the results with a written report


[//]: # (Image References)

[image1]: ./examples/placeholder.png "Model Visualization"
[image2]: ./examples/placeholder.png "Grayscaling"
[image3]: ./examples/placeholder_small.png "Recovery Image"
[image4]: ./examples/placeholder_small.png "Recovery Image"
[image5]: ./examples/placeholder_small.png "Recovery Image"
[image6]: ./examples/placeholder_small.png "Normal Image"
[image7]: ./examples/placeholder_small.png "Flipped Image"

## Rubric Points

---
### Files Submitted & Code Quality

#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode

My project includes the following files:
* [model.py](https://github.com/deepanshu96/carp3/blob/master/model.py) containing the script to create and train the model.
* [model.ipynb](https://github.com/deepanshu96/carp3/blob/master/model.ipynb) the jupyter notebook of the model which I used.
* [drive.py](https://github.com/deepanshu96/carp3/blob/master/drive.py) for driving the car in autonomous mode.
* [model.h5](https://github.com/deepanshu96/carp3/blob/master/model.h5) containing a trained convolution neural network. 
* [writeup_report.md](https://github.com/deepanshu96/carp3/blob/master/writeup_template.md) summarizing the results.
* [run1.mp4](https://github.com/deepanshu96/carp3/blob/master/run1.mp4) is the video generated by the car in autonomous mode.
* The screen recording of car, driving on track one is [here](https://www.youtube.com/watch?v=QKrsjrtR-i8).

#### 2. Submission includes functional code
Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing 
```sh
python drive.py model.h5
```

#### 3. Submission code is usable and readable

The [model.py file](https://github.com/deepanshu96/carp3/blob/master/model.py) contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model.
Apart from it I have also included the pre trained jupyter notebook which is [model.ipynb](https://github.com/deepanshu96/carp3/blob/master/model.ipynb). 

### Model Architecture and Training Strategy

#### 1. An appropriate model architecture has been employed

My model is based on the model that nvidia self driving car team used. Here is the [link](https://devblogs.nvidia.com/deep-learning-self-driving-cars/) of their deep learning model. It uses convolution nueral networks followed by layers of simple conventional neural networks. My model contains 5 convolution layers with relu activation followed by 4 layers of neural network. It helped the car to efficiently obtain different features of the path ahead and decide the steering angle based on the information. 

#### 2. Attempts to reduce overfitting in the model

I did not use maxpooling or dropout layers since the number of epochs I used were less, this also helped in reducing the overall and validation error.

The model was trained and validated on different data sets to ensure that the model was not overfitting (code line 10-16). The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.The validation set was derived by splitting the given data into training and validation data. 

I also used generators in order to reduce the space or memory needed, this helped in removing the memory out of bounds exception which was encountered prior to it. 

#### 3. Model parameter tuning

The model used an adam optimizer, so the learning rate was not tuned manually.

#### 4. Appropriate training data

I used the training data provided by udacity in the file data.zip. I applied various transformation in order to create new or more data. For details about how I created the training data, see the next section. 

### Model Architecture and Training Strategy

#### 1. Solution Design Approach

The overall strategy for deriving a model architecture was to improve the overall behaviour of the autonomous driving of the car so that it remains on the road and does not fall over the edges.

My first step was to use a convolution neural network model similar to the model that was used by the nvidia self driving car team. I thought this model might be appropriate because it gave low validation and training errors and was pretested on actual self driving car by the nvidia team. I also tried to use le net model architecture but it did not give accurate results as the car was unable to complete the track and fell over the edges.

At first I used dropout layers in order to reduce the overfitting but due to it the model was not training well and hence I decided to remove any dropout layers which reduced the validation errors. I also used less number of epochs so that the model does not overfit. At last I used adam optimizer which helps the model to learn the parameters efficiently. 

The final step was to run the simulator to see how well the car was driving around track one. In the initial attempts the car was going away from road but after many refinements and image processing(discussed below), the car was able to drive till the first turn after the bridge. After that I decided to use the left and right camera images also with a steering angle correction. 

At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road.

#### 2. Final Model Architecture

My final model consisted of the following layers:

| Layer         		|     Description	        					| 
|:---------------------:|:---------------------------------------------:| 
| Lambda         		| Output - (None, 160, 320, 3)   							| 
| Cropping         		| Output - (None, 90, 320, 3)   							| 
| Convolution      	| Output - (None, 43, 158, 24) 	|
| RELU					|												|
| Convolution      	| Output - (None, 20, 77, 36) 	|
| RELU					|												|
| Convolution      	| Output - (None, 8, 37, 48) 	|
| RELU					|												|
| Convolution      	| Output - (None, 6, 35, 64) 	|
| RELU					|												|
| Convolution      	| Output - (None, 4, 33, 64) 	|
| RELU					|												|											|
| Flatten Layers		| Output - (None, 8448)    		|
| Fully Connected Layers		| Output = (None, 100)     		|
| Fully Connected Layers		| Output = (None, 50)   		|
| Fully Connected Layers		| Output = (None, 10)     		|
| Fully Connected Layers		| Output = (None, 1)     		|

#### 3. Creation of the Training Set & Training Process

I used the training data provided by the udacity in the data.zip file. Since the data had limited amount of images I added or created addtional images by flipping each image in the dataset. 

I also used the left and right camera images in with a steering angle correction of 0.1 in order to navigate through more steep turns on the track one in the udacity simulator. 

Finally I randomly shuffled the data set and put 20% of the data into a validation set. 

After that I normalized the images using lambda function in keras and cropped the images so the only the track images were feeded to the model. This helped remove unnecessary information likes trees, mountains etc. which could have resulted in generation wrong results. 

The images were preprocessed in batches using the generator function and were used by model using the fit_generator function in keras. 

The images from the car camera are shown below:-


### Center

![alt text](https://github.com/deepanshu96/carp3/blob/master/one.png)

### Left

![alt text](https://github.com/deepanshu96/carp3/blob/master/two.png)

### Right

![alt text](https://github.com/deepanshu96/carp3/blob/master/three.png)


I used this training data for training the model. The validation set helped determine if the model was over or under fitting. The ideal number of epochs used were 5. I used an adam optimizer so that manually training the learning rate wasn't necessary.
